import streamlit as st
import pandas as pd

from core.config import load_config
from services.keepa_client import KeepaClient
from services.amazon_html import search_related_html, enrich_product_info, scrape_listing_text
from services.keyword_mining import mine_keywords_from_cluster, attach_bsr_signal
from core.exporters import to_csv_bytes, to_csv_bytes_many

st.set_page_config(page_title="Keyword Intelligence", page_icon="ğŸ”", layout="wide")
st.title("ğŸ” ç«å“å…³é”®è¯ Â· é€†å‘åˆ†æï¼ˆKeepa + HTML + è¯é¢‘ï¼‰")

cfg = load_config("config.yaml")
domain_name = st.selectbox("ç«™ç‚¹", list(cfg.keepa.domain_map.keys()), index=0)
seed_asin = st.text_input("è¾“å…¥ç§å­ ASINï¼ˆå¦‚ B08CH9HFSCï¼‰").strip().upper()
max_cluster = st.slider("æœ€å¤šæ‹‰å–å¤šå°‘ä¸ªç›¸å…³ç«å“ï¼ˆKeepa+HTML åˆå¹¶å»é‡åå–å‰Nä¸ªï¼‰", 10, 300, 80, 10)

colA, colB = st.columns([1,1])
with colA:
    do_keepa = st.checkbox("ä½¿ç”¨ Keepa ç›¸å…³ ASIN é€šé“", value=True)
with colB:
    do_html = st.checkbox("ä½¿ç”¨ HTML å›é€€é€šé“", value=True)

if st.button("å¼€å§‹åˆ†æ", disabled=(not seed_asin)):
    # 1) ç›¸å…³ ASIN èšç±»
    all_asins = set()
    keepa_err = None
    if do_keepa:
        with st.spinner("Keepa æŠ“å–ç›¸å…³ ASIN..."):
            kc = KeepaClient(cfg.keepa.api_key, cfg.keepa.domain_map, cfg.keepa.timeout, cfg.keepa.retries)
            rel, keepa_err = kc.product_related(seed_asin, domain_name, cfg.keepa.history)
            all_asins.update(rel)
    if keepa_err:
        st.warning(f"Keepa è­¦å‘Šï¼š{keepa_err}")

    if do_html:
        with st.spinner("HTML å›é€€æŠ“å–ç›¸å…³ ASIN..."):
            rel_html = search_related_html(seed_asin, domain_name)
            all_asins.update(rel_html)

    all_asins = sorted([a for a in all_asins if a and len(a)==10 and a.upper()!=seed_asin])[:max_cluster]
    st.info(f"åˆå¹¶å»é‡åç›¸å…³ ASIN æ•°ï¼š{len(all_asins)}")

    if not all_asins:
        st.error("æ²¡æœ‰æ‹¿åˆ°ç›¸å…³ ASINï¼Œæ— æ³•ç»§ç»­ã€‚è¯·æ¢ä¸€ä¸ªç§å­ ASIN æˆ–ç¨åé‡è¯•ã€‚")
        st.stop()

    # 2) è¡¥å…¨åŸºæœ¬ä¿¡æ¯ï¼ˆä»·æ ¼/è¯„åˆ†/è¯„è®ºæ•°/å“ç‰Œï¼‰
    with st.spinner("è¡¥å…¨åŸºæœ¬ä¿¡æ¯ï¼ˆæ ‡é¢˜/ä»·æ ¼/è¯„åˆ†/è¯„è®º/å“ç‰Œï¼‰..."):
        df_full = enrich_product_info(all_asins, domain_name)

    # 3) æŠ“å–æ–‡æ¡ˆæ–‡æœ¬ï¼ˆæ ‡é¢˜/äº”ç‚¹/A+ï¼‰
    with st.spinner("æŠ“å– Listing æ–‡æ¡ˆæ–‡æœ¬ï¼ˆæ ‡é¢˜/è¦ç‚¹/A+ï¼‰..."):
        texts = scrape_listing_text(all_asins, domain_name)  # è¿”å› dict[asin] = {"title","bullets","aplus","brand"}

    # 4) å…³é”®è¯æŒ–æ˜ï¼ˆè¯é¢‘ + æƒé‡ + å»å™ª + ç›¸å…³æ€§é˜ˆå€¼ï¼‰
    with st.spinner("å…³é”®è¯æŒ–æ˜ä¸æ‰“åˆ†..."):
        kw_table, debug_rows = mine_keywords_from_cluster(texts, cfg.keyword_mining)

    st.subheader("ğŸ·ï¸ ç«å“å…³é”®è¯æ¦œå•ï¼ˆæŒ‰å¾—åˆ†/è¦†ç›–æ’åºï¼‰")
    st.dataframe(kw_table.head(cfg.keyword_mining.max_top), use_container_width=True)
    st.download_button(
        "â¬‡ï¸ ä¸‹è½½å…³é”®è¯æ¦œå•ï¼ˆCSVï¼‰",
        to_csv_bytes(kw_table.head(cfg.keyword_mining.max_top)),
        file_name=f"{seed_asin}_keyword_leaderboard.csv",
        mime="text/csv",
    )

    # 5) å¯é€‰ï¼šå¯¹æ ¸å¿ƒå…³é”®è¯é™„åŠ  BSR åŒæ­¥ä¿¡å·ï¼ˆç”¨ Keepa çš„ BSR æ›²çº¿åšä½è¯ï¼‰
    if cfg.keyword_mining.bsr_correlation_window and cfg.keepa.api_key:
        with st.spinner("è®¡ç®— BSR åŒæ­¥ä¿¡å·ï¼ˆé‡‡æ · Top 50 ç›¸å…³ ASINï¼‰..."):
            kw_table2 = attach_bsr_signal(
                kw_table.head(cfg.keyword_mining.max_top).copy(),
                candidate_asins=all_asins[:50],
                keepa_client=kc,
                window=cfg.keyword_mining.bsr_correlation_window
            )
        st.subheader("ğŸ“ˆ é™„å¸¦ BSR åŒæ­¥ä¿¡å·çš„å…³é”®è¯æ¦œå•")
        st.dataframe(kw_table2.head(cfg.keyword_mining.max_top), use_container_width=True)
        st.download_button(
            "â¬‡ï¸ ä¸‹è½½ï¼ˆå« BSR ä¿¡å·ï¼‰CSV",
            to_csv_bytes(kw_table2.head(cfg.keyword_mining.max_top)),
            file_name=f"{seed_asin}_keyword_leaderboard_bsr.csv",
            mime="text/csv",
        )
    else:
        st.info("æœªå¯ç”¨æˆ–æ— æ³•è®¡ç®— BSR åŒæ­¥ä¿¡å·ï¼ˆéœ€è¦ Keepa API Key ä¸”é…ç½®äº†çª—å£ï¼‰ã€‚")

    # 6) è°ƒè¯•/é€æ˜åº¦è¾“å‡ºï¼šåŸå§‹æ–‡æœ¬ä¸å‚ä¸æ ·æœ¬
    with st.expander("ğŸ” è°ƒè¯•ä¸å¯è¿½æº¯ï¼ˆæ ·æœ¬/æ–‡æœ¬åˆ‡ç‰‡ï¼‰"):
        st.write("ç”¨äºæŒ–æ˜çš„æ ·æœ¬ç»Ÿè®¡ï¼š", len(debug_rows))
        st.dataframe(pd.DataFrame(debug_rows).head(200), use_container_width=True)

    # 7) ä¸€é”®æ‰“åŒ…ä¸‹è½½
    from datetime import datetime
    zip_buf = to_csv_bytes_many({
        "competitor_meta.csv": df_full,
        "keyword_leaderboard.csv": kw_table.head(cfg.keyword_mining.max_top),
        "debug_samples.csv": pd.DataFrame(debug_rows),
    })
    st.download_button(
        "ğŸ“¦ ä¸€é”®æ‰“åŒ…ä¸‹è½½ï¼ˆZipï¼‰",
        data=zip_buf.getvalue(),
        file_name=f"keyword_intel_{seed_asin}_{datetime.now().date()}.zip",
        mime="application/zip",
    )
